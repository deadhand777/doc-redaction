{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Document Redaction Automation Service","text":""},{"location":"#project-structure","title":"Project Structure","text":"<p>The project is organized as follows:</p> <p></p> Path Type Description Root Directory <code>pyproject.toml</code> Config Project configuration, dependencies, and build settings <code>Makefile</code> Build Development automation commands and build scripts <code>README.md</code> Doc Main project documentation and overview <code>uv.lock</code> Lock UV package manager lock file for reproducible builds /data/ Directory Document processing data storage <code>/data/contract/</code> Directory Original PDF contract files for processing <code>/data/markdown/</code> Directory Converted markdown files from PDF conversion <code>/data/confidential/</code> Directory JSON files containing detected sensitive data <code>/data/redact/</code> Directory Final redacted document outputs /src/doc_redaction/ Directory Main application source code <code>/src/doc_redaction/__init__.py</code> Module Package initialization file <code>/src/doc_redaction/agent.py</code> Module AI agent creation and configuration <code>/src/doc_redaction/output.py</code> Module Pydantic models for structured outputs (SensitiveData) <code>/src/doc_redaction/promt.py</code> Module System prompts for different AI agents <code>/src/doc_redaction/utils.py</code> Module Utility functions and custom exceptions <code>/src/doc_redaction/workflow.py</code> Module Main document processing workflow orchestration /src/doc_redaction/tool/ Directory Processing tools and utilities <code>/src/doc_redaction/tool/__init__.py</code> Module Tool package initialization <code>/src/doc_redaction/tool/detect_sensitive_data.py</code> Tool Sensitive information detection using regex patterns <code>/src/doc_redaction/tool/redact_sensitive_data.py</code> Tool Document redaction and content sanitization <code>/src/doc_redaction/tool/tool_utils.py</code> Tool Utility functions for tool operations <code>/src/doc_redaction/tool/document_processing.py</code> Tool Large document processing and chunking system /tests/ Directory Test suite for all application components <code>/tests/test_*.py</code> Tests Comprehensive unit and integration tests"},{"location":"#tooling","title":"Tooling","text":"<p>The templete utilizes the following tools for development, testing, and deployment:</p> <ul> <li>uv for dependency management</li> <li>CI/CD with GitHub Actions</li> <li>Pre-commit hooks with pre-commit</li> <li>Code quality with ruff, ty and prettier</li> <li>Documentation with MkDocs</li> <li>Compatibility testing for multiple versions of Python with tox-uv</li> <li>Containerization with Docker</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>See Getting Started</p>"},{"location":"#architecture","title":"Architecture","text":"<p>See Architecture</p>"},{"location":"#modules-and-features","title":"Modules and Features","text":"<p>See Modules documentation.</p>"},{"location":"agentic_workflow/","title":"Agent Workflow","text":"<p>The service is a agentic system composed of a multi-step workflow.</p> <p>The three-stage document processing pipeline converts, analyzes, and redacts sensitive information from PDF contracts using AI agents powered by AWS Bedrock models.</p> <p></p>"},{"location":"agentic_workflow/#stage-1-pdf-to-markdown-conversion","title":"Stage 1: PDF to Markdown Conversion","text":"<p>Multimodal agent uses AI vision capabilities:</p> <ul> <li>Reads and understands PDF content</li> <li>Converts PDF structure and content to clean markdown format</li> <li>Preserves document structure, formatting, and content hierarchy</li> </ul> <p>Output: Markdown file representing the original PDF document</p>"},{"location":"agentic_workflow/#stage-2-sensitive-data-detection","title":"Stage 2: Sensitive Data Detection","text":"<p>Detection agent specialized for sensitive information identification</p> <ul> <li> <p>Analyzes document content using structured output with SensitiveData model</p> </li> <li> <p>Identifies and extracts sensitive information including:</p> </li> <li>Personal information (names, emails, phone numbers)</li> <li>Company details (names, addresses, registration numbers)</li> <li>Document metadata and analysis information</li> <li>Applies strict guidelines: only extract information actually present in text</li> </ul> <p>Output: Structured JSON file with detected sensitive information</p>"},{"location":"agentic_workflow/#stage-3-document-redaction","title":"Stage 3: Document Redaction","text":"<p>Redaction agent focused on content sanitization</p> <ul> <li>Systematically redacts all sensitive information identified in Stage 2</li> <li>Preserves document structure and non-sensitive content</li> <li>Maintains document readability while removing confidential data</li> </ul> <p>Output: Redacted markdown file with sensitive information removed</p>"},{"location":"agentic_workflow/#agent-architecture","title":"Agent Architecture","text":"<p>Specialized Agents: Each stage uses a purpose-built agent with specific: - System prompts tailored to the task - Curated tool sets for required operations - Model configurations optimized for the workload</p>"},{"location":"agentic_workflow/#output-artifacts","title":"Output Artifacts","text":"<ul> <li>Converted Document: Clean markdown representation of the original PDF</li> <li>Sensitive Data Catalog: Structured JSON with all detected sensitive information</li> <li>Redacted Document: Sanitized version safe for broader distribution</li> <li>Process Metrics: Detailed logging and usage statistics for each stage</li> </ul> <p>This workflow enables automated, AI-powered document redaction with full traceability and structured output suitable for compliance and audit requirements.</p>"},{"location":"agentic_workflow/#example-input-and-output","title":"Example Input and Output","text":"<p>Sample input and output artifacts can be found in the data directory of this repository.</p> Raw Contract Converted Document Sensitive Data Catalog Redacted Document Raw spielbank_rocketbase_dienstleistungsvertrag Converted spielbank_rocketbase_dienstleistungsvertrag Extracted spielbank_rocketbase_dienstleistungsvertrag Redacted spielbank_rocketbase_dienstleistungsvertrag Raw rocketbase_aws_agreement Converted rocketbase_aws_agreement Extracted rocketbase_aws_agreement Redacted rocketbase_aws_agreement Raw spielbank_rocketbase_vertrag Converted spielbank_rocketbase_vertrag Extracted spielbank_rocketbase_vertrag Redacted spielbank_rocketbase_vertrag"},{"location":"architecture/","title":"Architecture","text":"<p>TODO</p>"},{"location":"getting_started/","title":"Getting started","text":"<p>Here's how to set up <code>doc-redaction</code> for local development. Please note this documentation assumes you already have <code>uv</code> and <code>Git</code> installed and ready to go.</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/deadhand777/doc-redaction.git\n</code></pre> <ol> <li>Now install the environment. Navigate into the directory</li> </ol> <pre><code>cd doc-redaction\n</code></pre> <p>Then, install and activate the environment with:</p> <pre><code>uv sync\n</code></pre> <ol> <li>Install pre-commit to run linters/formatters at commit time:</li> </ol> <pre><code>uv run pre-commit install\n</code></pre> <p>Congratulations, now your setup is completed!</p> <ol> <li>Run the workflow on a sample PDF document:</li> </ol> <pre><code>uv run src/doc_redaction/workflow.py --key spielbank_rocketbase_vertrag\n</code></pre>"},{"location":"modules/","title":"Modules","text":""},{"location":"modules/#agent-modules","title":"Agent Modules","text":""},{"location":"modules/#create_agent","title":"create_agent","text":"<p>Create and return a configured Agent.</p> <ul> <li>system_prompt: Required non-empty instructional prompt.</li> <li>name: Optional agent name (default: \"Strands Agent\").</li> <li>model: Optional model. Falls back to default bedrock_model if None.</li> <li>tools: Optional iterable of tool specs/objects. Converted internally to a list.</li> </ul> <p>Raises:</p> Type Description <code>MissingArgumentError</code> <p>If system_prompt is missing or empty.</p> <code>TypeError</code> <p>If system_prompt is not a string.</p> Source code in <code>src/doc_redaction/agent.py</code> <pre><code>def create_agent(\n    system_prompt: str,\n    name: str | None = \"Strands Agent\",\n    model: BedrockModel | OllamaModel | None = bedrock_model,\n    tools: Sequence[str | dict[str, str] | Any] | None = None,\n) -&gt; Agent:\n    \"\"\"\n    Create and return a configured Agent.\n\n    - system_prompt: Required non-empty instructional prompt.\n    - name: Optional agent name (default: \"Strands Agent\").\n    - model: Optional model. Falls back to default bedrock_model if None.\n    - tools: Optional iterable of tool specs/objects. Converted internally to a list.\n\n    Raises:\n        MissingArgumentError: If system_prompt is missing or empty.\n        TypeError: If system_prompt is not a string.\n    \"\"\"\n    if not isinstance(system_prompt, str):\n        raise ParameterTypeError(\"system_prompt\", \"a string\")\n    if not system_prompt.strip():\n        raise MissingArgumentError(\"system_prompt\")\n\n    # Fallback to default model if none provided\n    if model is None:\n        model = bedrock_model\n\n    # Normalize tools to a list (avoid mutable default pitfalls)\n    tools_list: list[str | dict[str, str] | Any] | None = list(tools) if tools else None\n\n    agent: Agent = Agent(\n        model=model,\n        system_prompt=system_prompt.strip(),\n        tools=tools_list,\n    )\n\n    if type(model) is BedrockModel:\n        agent.name = name\n\n    logger.info(\n        \"Agent created successfully\",\n        extra={\n            \"agent_name\": name,\n            \"model_id\": getattr(model, \"model_id\", \"unknown\"),\n            \"tools_count\": len(tools_list) if tools_list else 0,\n        },\n    )\n\n    return agent\n</code></pre>"},{"location":"modules/#agentic-workflow-modules","title":"Agentic Workflow Modules","text":""},{"location":"modules/#run_doc_processing_wf","title":"run_doc_processing_wf","text":"Source code in <code>src/doc_redaction/workflow.py</code> <pre><code>def run_doc_processing_wf(key: str = \"spielbank_rocketbase_vertrag\"):\n    if not isinstance(key, str) or not key:\n        raise InvalidDocumentKeyError()\n\n    # Step 0: Assess document quality\n    DOC_QUALITY_IN: str = f\"{DIR}{PREFIX['contract']}{key}{FORMAT['pdf']}\"\n    DOC_QUALITY_OUT: str = f\"{DIR}{PREFIX['quality']}{key}{FORMAT['json']}\"\n    doc_quality: dict[str, Any] = assess_doc_quality(\n        file_path=DOC_QUALITY_IN,\n        output_path=DOC_QUALITY_OUT,\n    )\n\n    # Step 1: Convert input contract from PDF to markdwon format using vision model\n    multimodal_agent: Agent = create_agent(\n        name=\"multimodal_agent\",\n        system_prompt=CONVERTER_SYSTEM_PROMPT,\n        tools=[\n            # file_write,\n            image_reader,\n            merge_markdown_strings,\n            save_file,\n            remove_temp_files,\n        ],\n    )\n    CONVERT_IN: list[str] = pdf_to_png(\n        pdf_path=f\"{DIR}{PREFIX['contract']}{key}{FORMAT['pdf']}\",\n        output_dir=f\"{DIR}{PREFIX['temp']}\",\n    )\n    CONVERT_OUT: str = f\"{DIR}{PREFIX['markdown']}{key}{FORMAT['md']}\"\n    CONVERT_USER_PROMPT: str = f\"\"\"\n    Convert the following document to markdown: {CONVERT_IN}.\n    Save the result to {CONVERT_OUT}.\n    Finally, clean up temporary files using remove_temp_files tool.\n    \"\"\"\n    convert_result: AgentResult = multimodal_agent(CONVERT_USER_PROMPT)\n\n    convert_result_token_usage = token_usage(\n        content=convert_result.metrics.accumulated_usage,\n        model=multimodal_agent.model.get_config()[\"model_id\"],\n    )\n    logger.info(f\"Conversion stopping reason: {convert_result.stop_reason}\")\n    logger.info(f\"{multimodal_agent.name} token usage: {convert_result_token_usage}\")\n    logger.info(f\"Saved conversion result in {CONVERT_OUT}\")\n\n    # Step 2: Detect sensitve information\n    DETECT_OUT: str = f\"{DIR}{PREFIX['confidential']}{key}{FORMAT['json']}\"\n    DETECT_USER_PROMPT: str = f\"\"\"\n    Analyze the following document: {convert_result!s}.\n    Detect sensitive data.\n    \"\"\"\n\n    detector_agent: Agent = create_agent(\n        name=\"detector_agent\",\n        system_prompt=DETECTION_SYSTEM_PROMPT,\n        tools=[\n            current_time,\n            detect_sensitive_data,\n            omit_empty_keys,\n        ],\n    )\n    detector_agent.model.update_config(\n        model_id=MODEL_IDS[\"haiku\"],\n        max_tokens=64000,\n    )\n\n    detector_result: str = detector_agent.structured_output(\n        output_model=SensitiveData,\n        prompt=DETECT_USER_PROMPT,\n    ).model_dump_json(indent=2)\n\n    save_as_json(data=detector_result, filename=DETECT_OUT)\n\n    detector_result_token_usage: dict[str, dict[str, Any]] = {\n        token_type: token_usage(\n            content=content,\n            token_type=token_type,\n            model=detector_agent.model.get_config()[\"model_id\"],\n        )\n        for token_type, content in {\n            \"inputTokens\": DETECT_USER_PROMPT,\n            \"outputTokens\": detector_result,\n        }.items()\n    }\n\n    logger.info(f\"{detector_agent.name} token usage: {detector_result_token_usage}\")\n    logger.info(f\"Saved detection result in {DETECT_OUT}\")\n\n    # Step 3: Redact sensitive information\n    REDACT_OUT: str = f\"{DIR}{PREFIX['redact']}{key}{FORMAT['md']}\"\n\n    REDACTED_USER_PROMPT: str = f\"\"\"\n    Analyze the following document: {convert_result!s}.\n    Redact all information provided in {detector_result!s} except for the document_analysis field.\n    Save the result to {REDACT_OUT}.\n    \"\"\"\n\n    redact_agent: Agent = create_agent(\n        name=\"redact_agent\",\n        system_prompt=REDACTED_SYSTEM_PROMPT,\n        tools=[save_file, redact_sensitive_data],\n    )\n    redact_agent.model.update_config(\n        model_id=MODEL_IDS[\"haiku\"],\n        max_tokens=64000,\n    )\n\n    result_redacted: AgentResult = redact_agent(REDACTED_USER_PROMPT)\n    redacted_result_token_usage = token_usage(\n        content=result_redacted.metrics.accumulated_usage,\n        model=redact_agent.model.get_config()[\"model_id\"],\n    )\n    logger.info(f\"Conversion stopping reason: {result_redacted.stop_reason}\")\n    logger.info(f\"{redact_agent.name} token usage: {redacted_result_token_usage}\")\n    logger.info(f\"Saved redaction result in {REDACT_OUT}\")\n\n    # Step 4: Summarize token usage\n    all_agents_tokens: dict[str, dict[str, Any]] = {\n        \"multimodal_agent\": detector_result_token_usage,\n        \"detector_agent\": convert_result_token_usage,\n        \"redact_agent\": redacted_result_token_usage,\n    }\n    token_summary: str = summarize_token_usage(all_agents_tokens)\n    TOKEN_SUMMARY_OUT: str = f\"{DIR}{PREFIX['token']}{key}{FORMAT['json']}\"\n    save_as_json(data=token_summary, filename=TOKEN_SUMMARY_OUT)\n\n    return doc_quality, detector_result, token_summary\n</code></pre>"},{"location":"modules/#output-modules","title":"Output Modules","text":""},{"location":"modules/#sensitivedata","title":"SensitiveData","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents sensitive data detected in a document.</p> Source code in <code>src/doc_redaction/output.py</code> <pre><code>class SensitiveData(BaseModel):\n    \"\"\"Represents sensitive data detected in a document.\"\"\"\n\n    document_analysis: DocumentAnalysis = Field(..., description=\"Metadata about the analyzed document.\")\n    parties: list[Party] = Field(..., description=\"Information about the parties involved in the contract.\")\n    representative: list[Representative] = Field(..., description=\"Information about the representatives of the parties.\")\n    contract_terms: ContractTerms = Field(..., description=\"Key terms and conditions of the contract.\")\n    risk_assessment: RiskAssessment = Field(..., description=\"Risk assessment of the contract.\")\n    data_protection_compliance: DataProtectionCompliance = Field(..., description=\"Data protection compliance details.\")\n</code></pre>"},{"location":"modules/#tool-modules","title":"Tool Modules","text":""},{"location":"modules/#detect_sensitive_data","title":"detect_sensitive_data","text":"<p>Tool for detecting sensitive data in markdown documents.</p>"},{"location":"modules/#tool.detect_sensitive_data.detect_sensitive_data","title":"<code>detect_sensitive_data(markdown_content)</code>","text":"<p>Detects and extracts sensitive information from markdown documents.</p> Source code in <code>src/doc_redaction/tool/detect_sensitive_data.py</code> <pre><code>@tool\ndef detect_sensitive_data(markdown_content: str) -&gt; dict[str, list[str]]:\n    \"\"\"Detects and extracts sensitive information from markdown documents.\"\"\"\n\n    text = remove_markdown_formatting(markdown_content)\n    results: dict[str, list[str]] = {}\n\n    # Mapping of result key -&gt; regex list or single regex\n    pattern_mapping = {\n        \"email_addresses\": [EMAIL_RE],\n        \"phone_numbers\": PHONE_REGEXES,\n        \"credit_card_numbers\": [CC_RE],\n        \"iban_numbers\": [IBAN_RE],\n        \"account_numbers\": [ACCOUNT_RE],\n        \"addresses\": ADDRESS_REGEXES,\n        \"people_names\": [NAME_RE],\n        \"currency_amounts\": CURRENCY_REGEXES,\n        \"percentages\": PERCENTAGE_REGEXES,\n        \"numbers\": NUMBER_REGEXES,\n    }\n\n    for key, regexes in pattern_mapping.items():\n        matches = set()\n        for regex in regexes:\n            for match in regex.findall(text):\n                # Additional filters for some types\n                if key == \"phone_numbers\" and len(re.sub(r\"[^\\d]\", \"\", match)) &lt; 7:\n                    continue\n                if key == \"credit_card_numbers\":\n                    digits = re.sub(r\"[^\\d]\", \"\", match)\n                    if not (13 &lt;= len(digits) &lt;= 19):\n                        continue\n                if key == \"people_names\" and match in COMMON_NON_NAMES:\n                    continue\n                matches.add(match)\n        if matches:\n            results[key] = list(matches)\n\n    # Add German &amp; English number words\n    numbers_set = set(results.get(\"numbers\", []))\n    for word in text.lower().split():\n        clean_word = word.strip(\".,;:!?\")\n        if clean_word in GERMAN_NUMBER_WORDS or clean_word in ENGLISH_NUMBER_WORDS:\n            numbers_set.add(clean_word)\n    if numbers_set:\n        results[\"numbers\"] = list(numbers_set)\n\n    return results\n</code></pre>"},{"location":"modules/#tool.detect_sensitive_data.remove_markdown_formatting","title":"<code>remove_markdown_formatting(markdown_text)</code>","text":"<p>Remove markdown formatting for cleaner analysis.</p> Source code in <code>src/doc_redaction/tool/detect_sensitive_data.py</code> <pre><code>def remove_markdown_formatting(markdown_text: str) -&gt; str:\n    \"\"\"Remove markdown formatting for cleaner analysis.\"\"\"\n    patterns = [\n        (r\"^#{1,6}\\s+\", \"\"),  # headers\n        (r\"\\*\\*(.+?)\\*\\*\", r\"\\1\"),  # bold\n        (r\"\\*(.+?)\\*\", r\"\\1\"),  # italic\n        (r\"__(.+?)__\", r\"\\1\"),  # underline\n        (r\"_(.+?)_\", r\"\\1\"),\n        (r\"`(.+?)`\", r\"\\1\"),  # inline code\n        (r\"```.*?```\", \"\", re.DOTALL),  # code blocks\n        (r\"\\[(.+?)\\]\\(.+?\\)\", r\"\\1\"),  # links\n        (r\"!\\[.*?\\]\\(.+?\\)\", \"\"),  # images\n        (r\"^---+$\", \"\", re.MULTILINE),  # hr\n        (r\"^\\s*[-*+]\\s+\", \"\", re.MULTILINE),  # unordered lists\n        (r\"^\\s*\\d+\\.\\s+\", \"\", re.MULTILINE),  # ordered lists\n        (r\"^&gt;\\s+\", \"\", re.MULTILINE),  # blockquotes\n    ]\n    text = markdown_text\n\n    for pat in patterns:\n        text = (\n            re.sub(pat[0], pat[1], text)  # if len(pat) == 2 else re.sub(pat[0], pat[1], text)  # flags=pat[2]\n        )\n\n    text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)  # normalize spacing\n    return re.sub(r\"[ \\t]+\", \" \", text).strip()\n</code></pre>"},{"location":"modules/#redact_sensitive_data","title":"redact_sensitive_data","text":"<p>Tool for redacting sensitive information from markdown documents.</p>"},{"location":"modules/#tool.redact_sensitive_data.apply_redactions","title":"<code>apply_redactions(content, rules, redaction_symbol, preserve_structure)</code>","text":"<p>Apply redaction rules to the content based on user specifications.</p> Source code in <code>src/doc_redaction/tool/redact_sensitive_data.py</code> <pre><code>def apply_redactions(content: str, rules: str, redaction_symbol: str, preserve_structure: bool) -&gt; str:\n    \"\"\"\n    Apply redaction rules to the content based on user specifications.\n    \"\"\"\n    rules_lower = rules.lower()\n\n    # Common patterns\n    patterns = {\n        \"email\": (\n            [r\"email\", r\"e-mail\", \"@\"],\n            r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",\n        ),\n        \"phone\": (\n            [r\"phone\", r\"telephone\", r\"number\"],\n            r\"(\\+?1[-.\\s]?)?\\(?([0-9]{3})\\)?[-.\\s]?([0-9]{3})[-.\\s]?([0-9]{4})\",\n        ),\n        \"ssn\": (\n            [r\"ssn\", r\"social security\", r\"social\"],\n            r\"\\b\\d{3}-?\\d{2}-?\\d{4}\\b\",\n        ),\n        \"credit_card\": (\n            [r\"credit card\", r\"card number\", r\"credit\"],\n            r\"\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b\",\n        ),\n        \"zip_code\": (\n            [r\"zip code\", r\"postal code\", r\"zip\"],\n            r\"\\b\\d{5}(?:-\\d{4})?\\b\",\n        ),\n        \"ip_address\": (\n            [r\"ip address\", r\"ip\"],\n            r\"\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b\",\n        ),\n        \"url\": (\n            [r\"url\", r\"link\", r\"website\"],\n            r'https?://[^\\s&lt;&gt;\"{}|\\\\^`\\[\\]]+',\n        ),\n        \"date\": (\n            [r\"date\", r\"birthday\", r\"birth\"],\n            r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b|\\b\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}\\b\",\n        ),\n        \"name\": (\n            [r\"name\", r\"person\", r\"individual\"],\n            r\"\\b[A-Z][a-z]+ [A-Z][a-z]+\\b\",\n        ),\n        \"address\": (\n            [r\"address\", r\"street\", r\"location\"],\n            r\"\\d+\\s+[A-Za-z\\s]+(?:Street|St|Avenue|Ave|Road|Rd|Drive|Dr|Lane|Ln|Boulevard|Blvd)\",\n        ),\n    }\n\n    def should_apply(keywords: list[str]) -&gt; bool:\n        return any(term in rules_lower for term in keywords)\n\n    redacted_content = content\n    for _, (keywords, pattern) in patterns.items():\n        if should_apply(keywords):\n            redacted_content = redact_pattern(redacted_content, pattern, redaction_symbol, preserve_structure)\n\n    # Handle custom terms\n    for term in extract_custom_terms(rules):\n        if term and len(term) &gt; 2:\n            pattern = re.escape(term)\n            redacted_content = redact_pattern(redacted_content, pattern, redaction_symbol, preserve_structure, case_insensitive=True)\n\n    return redacted_content\n</code></pre>"},{"location":"modules/#tool.redact_sensitive_data.extract_custom_terms","title":"<code>extract_custom_terms(rules)</code>","text":"<p>Extract potential custom terms to redact from the rules text. This is a simple approach - could be enhanced with NLP.</p> Source code in <code>src/doc_redaction/tool/redact_sensitive_data.py</code> <pre><code>def extract_custom_terms(rules: str) -&gt; list[str]:\n    \"\"\"\n    Extract potential custom terms to redact from the rules text.\n    This is a simple approach - could be enhanced with NLP.\n    \"\"\"\n    # Look for quoted terms or terms after \"redact\"\n    custom_terms = []\n\n    # Extract quoted terms\n    quoted_terms = re.findall(r\"['\\\"]([^'\\\"]+)['\\\"]\", rules)\n    custom_terms.extend(quoted_terms)\n\n    # Extract terms after \"redact\" or \"remove\"\n    redact_terms = re.findall(r\"(?:redact|remove|hide)\\s+(?:all\\s+)?([a-zA-Z\\s]+?)(?:\\s+(?:and|or|from)|$)\", rules, re.IGNORECASE)\n    for term in redact_terms:\n        term = term.strip()\n        if term and not any(common in term.lower() for common in [\"email\", \"phone\", \"number\", \"address\", \"name\", \"ssn\", \"credit\", \"card\"]):\n            custom_terms.append(term)\n\n    return custom_terms\n</code></pre>"},{"location":"modules/#tool.redact_sensitive_data.redact_pattern","title":"<code>redact_pattern(content, pattern, redaction_symbol, preserve_structure, case_insensitive=False)</code>","text":"<p>Redact matches of a specific pattern in the content.</p> Source code in <code>src/doc_redaction/tool/redact_sensitive_data.py</code> <pre><code>def redact_pattern(content: str, pattern: str, redaction_symbol: str, preserve_structure: bool, case_insensitive: bool = False) -&gt; str:\n    \"\"\"\n    Redact matches of a specific pattern in the content.\n    \"\"\"\n    flags = re.IGNORECASE if case_insensitive else 0\n\n    def replace_match(match):\n        matched_text = match.group(0)\n        if preserve_structure:\n            # Replace each character with a redaction character, preserving spaces and structure\n            redaction_char = \"\u2588\"\n            return re.sub(r\"\\S\", redaction_char, matched_text)\n        else:\n            return redaction_symbol\n\n    return re.sub(pattern, replace_match, content, flags=flags)\n</code></pre>"},{"location":"modules/#tool.redact_sensitive_data.redact_sensitive_data","title":"<code>redact_sensitive_data(tool, **kwargs)</code>","text":"<p>Redact sensitive information from markdown documents based on user specifications.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>ToolUse</code> <p>The tool use object containing tool execution details</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the tool</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ToolResult</code> <code>ToolResult</code> <p>The redacted markdown document</p> Source code in <code>src/doc_redaction/tool/redact_sensitive_data.py</code> <pre><code>def redact_sensitive_data(tool: ToolUse, **kwargs: Any) -&gt; ToolResult:\n    \"\"\"\n    Redact sensitive information from markdown documents based on user specifications.\n\n    Args:\n        tool: The tool use object containing tool execution details\n        **kwargs: Additional arguments passed to the tool\n\n    Returns:\n        ToolResult: The redacted markdown document\n    \"\"\"\n    try:\n        # Extract parameters\n        markdown_content = tool.get(\"input\", {}).get(\"markdown_content\", \"\")\n        redaction_rules = tool.get(\"input\", {}).get(\"redaction_rules\", \"\")\n        redaction_symbol = tool.get(\"input\", {}).get(\"redaction_symbol\", \"[REDACTED]\")\n        preserve_structure = tool.get(\"input\", {}).get(\"preserve_structure\", False)\n\n        if not markdown_content:\n            return {\n                \"toolUseId\": tool[\"toolUseId\"],\n                \"status\": \"error\",\n                \"content\": [{\"text\": \"Error: No markdown content provided\"}],\n            }\n\n        if not redaction_rules:\n            return {\n                \"toolUseId\": tool[\"toolUseId\"],\n                \"status\": \"error\",\n                \"content\": [{\"text\": \"Error: No redaction rules specified\"}],\n            }\n\n        # Parse redaction rules and apply redactions\n        redacted_content = apply_redactions(markdown_content, redaction_rules, redaction_symbol, preserve_structure)\n\n        return {\n            \"toolUseId\": tool[\"toolUseId\"],\n            \"status\": \"success\",\n            \"content\": [{\"text\": f\"Successfully redacted sensitive information based on rules: '{redaction_rules}'\\n\\nRedacted markdown document:\\n\\n{redacted_content}\"}],\n        }\n\n    except Exception as e:\n        return {\n            \"toolUseId\": tool[\"toolUseId\"],\n            \"status\": \"error\",\n            \"content\": [{\"text\": f\"Error processing redaction: {e!s}\"}],\n        }\n</code></pre>"},{"location":"modules/#data-storage","title":"Data Storage","text":"<p>Write a JSON-formatted string to a file and log the operation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>JSON string content to write.</p> required <code>filename</code> <code>str</code> <p>Destination file path. Existing content will be overwritten.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the file cannot be opened or written.</p> Logs <p>INFO: On successful save with the target file path.</p> Example <p>save_as_json(res, \"data/confidential/rocketbase_aws_agreement_sensitive_structures_v4.json\")</p> Source code in <code>src/doc_redaction/tool/store_data.py</code> <pre><code>@tool\ndef save_as_json(data: str, filename: str) -&gt; None:\n    \"\"\"Write a JSON-formatted string to a file and log the operation.\n\n    Parameters:\n        data: JSON string content to write.\n        filename: Destination file path. Existing content will be overwritten.\n\n    Returns:\n        None\n\n    Raises:\n        OSError: If the file cannot be opened or written.\n\n    Logs:\n        INFO: On successful save with the target file path.\n\n    Example:\n        save_as_json(res, \"data/confidential/rocketbase_aws_agreement_sensitive_structures_v4.json\")\n    \"\"\"\n    with open(filename, \"w\") as f:\n        f.write(data)\n    logger.info(f\"Saved structured output to {filename}\")\n</code></pre>"},{"location":"modules/#other-tools","title":"Other Tools","text":"<p>Write a formatted string to a file and log the operation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>String content to write.</p> required <code>filename</code> <code>str</code> <p>Destination file path. Existing content will be overwritten.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the file cannot be opened or written.</p> Logs <p>INFO: On successful save with the target file path.</p> Example <p>save_file(res, \"data/confidential/rocketbase_aws_agreement_sensitive_structures.json\")</p> Source code in <code>src/doc_redaction/tool/tool_utils.py</code> <pre><code>@tool\ndef save_file(data: str, filename: str) -&gt; None:\n    \"\"\"Write a formatted string to a file and log the operation.\n\n    Parameters:\n        data: String content to write.\n        filename: Destination file path. Existing content will be overwritten.\n\n    Returns:\n        None\n\n    Raises:\n        OSError: If the file cannot be opened or written.\n\n    Logs:\n        INFO: On successful save with the target file path.\n\n    Example:\n        save_file(res, \"data/confidential/rocketbase_aws_agreement_sensitive_structures.json\")\n    \"\"\"\n    output_dir = Path(filename).parent\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    with open(filename, \"w\") as f:\n        f.write(data)\n    logger.info(f\"Saved structured output to {filename}\")\n</code></pre> <p>Remove temporary files in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Directory path to remove.</p> <code>'data/temp/'</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/doc_redaction/tool/tool_utils.py</code> <pre><code>@tool\ndef remove_temp_files(path: str = \"data/temp/\") -&gt; None:\n    \"\"\"\n    Remove temporary files in the specified directory.\n\n    Parameters:\n        path: Directory path to remove.\n\n    Returns:\n        None\n    \"\"\"\n\n    shutil.rmtree(path)\n    logger.info(f\"Removed temporary files in directory: {path}\")\n</code></pre> <p>Parse a JSON object string and return only the items with non-empty values.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>A JSON-encoded object mapping string keys to lists of strings.</p> required <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>A dict[str, list[str]] containing only entries whose values are truthy (e.g., non-empty lists).</p> <p>Raises:</p> Type Description <code>JSONDecodeError</code> <p>If the input is not valid JSON.</p> Source code in <code>src/doc_redaction/tool/tool_utils.py</code> <pre><code>@tool\ndef omit_empty_keys(s: str) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Parse a JSON object string and return only the items with non-empty values.\n\n    Args:\n        s: A JSON-encoded object mapping string keys to lists of strings.\n\n    Returns:\n        A dict[str, list[str]] containing only entries whose values are truthy (e.g., non-empty lists).\n\n    Raises:\n        json.JSONDecodeError: If the input is not valid JSON.\n    \"\"\"\n    return {key: value for key, value in json.loads(s).items() if value}\n</code></pre>"},{"location":"modules/#utility-modules","title":"Utility Modules","text":""},{"location":"modules/#this-section-includes-common-utility-functions","title":"This section includes common utility functions.","text":""},{"location":"modules/#save_as_json","title":"save_as_json","text":"<p>Write a JSON-formatted string to a file and log the operation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>JSON string content to write.</p> required <code>filename</code> <code>str</code> <p>Destination file path. Existing content will be overwritten.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the file cannot be opened or written.</p> Logs <p>INFO: On successful save with the target file path.</p> Example <p>save_as_json(res, \"data/confidential/rocketbase_aws_agreement_sensitive_structures.json\")</p> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>def save_as_json(data: str, filename: str) -&gt; None:\n    \"\"\"Write a JSON-formatted string to a file and log the operation.\n\n    Parameters:\n        data: JSON string content to write.\n        filename: Destination file path. Existing content will be overwritten.\n\n    Returns:\n        None\n\n    Raises:\n        OSError: If the file cannot be opened or written.\n\n    Logs:\n        INFO: On successful save with the target file path.\n\n    Example:\n        save_as_json(res, \"data/confidential/rocketbase_aws_agreement_sensitive_structures.json\")\n    \"\"\"\n    output_dir = Path(filename).parent\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    with open(filename, \"w\") as f:\n        f.write(data)\n    logger.info(f\"Saved structured output to {filename}\")\n</code></pre>"},{"location":"modules/#get_pdf_page_count","title":"get_pdf_page_count","text":"<p>Return the number of pages in a PDF file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the local PDF file.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Total number of pages in the PDF.</p> <p>Raises:</p> Type Description <code>PDFProcessingError</code> <p>If the file cannot be opened, is not a valid PDF, or the page count cannot be determined.</p> Example <p>page_count = get_pdf_page_count(\"path/to/file.pdf\") print(f\"The document has {page_count} pages.\")</p> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>def get_pdf_page_count(file_path: str) -&gt; int:\n    \"\"\"\n    Return the number of pages in a PDF file.\n\n    Parameters:\n        file_path (str): Path to the local PDF file.\n\n    Returns:\n        int: Total number of pages in the PDF.\n\n    Raises:\n        PDFProcessingError: If the file cannot be opened, is not a valid PDF, or the page count cannot be determined.\n\n    Example:\n        page_count = get_pdf_page_count(\"path/to/file.pdf\")\n        print(f\"The document has {page_count} pages.\")\n    \"\"\"\n    try:\n        with open(file_path, \"rb\") as file:\n            pdf_reader = pypdf.PdfReader(file)\n            return len(pdf_reader.pages)\n    except Exception as e:\n        raise PDFProcessingError(file_path, e) from e\n</code></pre>"},{"location":"modules/#get_file_size","title":"get_file_size","text":"<p>Return the size of a file in bytes.</p> <pre><code>Parameters:\n    file_path (str): Path to the file.\n\nReturns:\n    int: File size in bytes.\n\nRaises:\n    FileNotFoundError: If the file does not exist.\n    OSError: If the size cannot be retrieved due to an OS-related error.\n\nExample:\n    size = get_file_size(\"/path/to/file.txt\")\n    print(f\"File size: {size} bytes\")\n</code></pre> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>def get_file_size(file_path: str) -&gt; int:\n    \"\"\"\n    Return the size of a file in bytes.\n\n        Parameters:\n            file_path (str): Path to the file.\n\n        Returns:\n            int: File size in bytes.\n\n        Raises:\n            FileNotFoundError: If the file does not exist.\n            OSError: If the size cannot be retrieved due to an OS-related error.\n\n        Example:\n            size = get_file_size(\"/path/to/file.txt\")\n            print(f\"File size: {size} bytes\")\n    \"\"\"\n    return os.path.getsize(file_path)\n</code></pre>"},{"location":"modules/#invalidcontenttype","title":"InvalidContentType","text":"<p>               Bases: <code>TypeError</code></p> <p>Raised when content is neither str nor int.</p> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>class InvalidContentType(TypeError):\n    \"\"\"Raised when content is neither str nor int.\"\"\"\n\n    def __init__(self, actual_type: type):\n        super().__init__(f\"Content must be str or int, got {actual_type.__name__}\")\n</code></pre>"},{"location":"modules/#invaliddocumentkeyerror","title":"InvalidDocumentKeyError","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when the provided document key is missing or invalid.</p> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>class InvalidDocumentKeyError(ValueError):\n    \"\"\"Raised when the provided document key is missing or invalid.\"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\"A document key must be provided as a non-empty string.\")\n</code></pre>"},{"location":"modules/#missingargumenterror","title":"MissingArgumentError","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when a required argument is missing.</p> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>class MissingArgumentError(ValueError):\n    \"\"\"Raised when a required argument is missing.\"\"\"\n\n    def __init__(self, argument_name: str) -&gt; None:\n        super().__init__(f\"{argument_name} must be provided\")\n</code></pre>"},{"location":"modules/#pdfprocessingerror","title":"PDFProcessingError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when PDF processing fails.</p> Source code in <code>src/doc_redaction/utils/commons.py</code> <pre><code>class PDFProcessingError(Exception):\n    \"\"\"Raised when PDF processing fails.\"\"\"\n\n    def __init__(self, file_path: str, e: Exception) -&gt; None:\n        super().__init__(f\"Could not determine page count for {file_path}: {e}\")\n        self.file_path = file_path\n</code></pre>"}]}